import random
import glob
import sys

"""
Markov Babbler

After being trained on text from various authors, it will
'babble' (generate random walks) and produce text that
vaguely sounds like the author of the training texts.
"""

# ------------------- Implementation Details: -------------------------------
# Our entire graph is a dictionary
#   - keys/states are ngrams represented as string or tuple, NOT a list 
#   (because we need to use states as dictionary keys, and lists are not hashable)
#   - values are either lists or Bags
# Starter states can be a list of states or a Bag
# When we pick a word, we transition to a new state
# e.g. suppose we are using bigrams and are at the state ‘the dog’ and we pick the word ‘runs’. 
# Our new state is ‘dog runs’, so we look up that state in our dictionary, and then get the next word, and so on…
# Ending states can generate a special "stop" symbol; we will use ‘EOL’.
#   If we generate the word ‘EOL’, then the sentence is over.
#   Since all words are lower-case, this won’t be confused for a legitimate word

# --------------------- Tasks --------------------------------
# class Babbler:

#    def __init__(self, n, seed=None): <---- consider what data structures you may need to create here

#    def add_file(self, filename): <---- already completed for you; calls add_sentence(), so do that next
#    def add_sentence(self, sentence): <---- your first port of call; read the comments and plan out your steps
#   
#    def get_starters(self):
#    def get_stoppers(self):
#    def get_successors(self, ngram):
#    def get_all_ngrams(self):
#    def has_successor(self, ngram):
#    def get_random_successor(self, ngram):
#
#    def babble(self):


class Babbler:
    
    def __init__(self, n, seed=None):
        """
        n: length of an n-gram for state
        seed: seed for a random number generation (None by default)
        """
        self.n = n 
        if seed != None: #seed:  
            random.seed(seed)

        # TODO: your code goes here
    
    
    def add_file(self, filename): #already written; no need to change
        """
        This method is already done for you. 
        It calls the add_sentence() method for each line of an input file after making it lower case.
        We are assuming input data has already been pre-processed so that each sentence is on a separate line.
        """
        for line in [line.rstrip().lower() for line in open(filename, errors='ignore').readlines()]:
            self.add_sentence(line)
    

    def add_sentence(self, sentence):
        """
        Process the given sentence (a string separated by spaces): 
        Break the sentence into words using split(); 
        Convert each word to lowercase using lower().
        Then start processing n-grams and updating your states.
        Remember to track starters (n-grams that begin sentences), stoppers (n-grams that end sentences), 
        and that any n-grams that stops a sentence should be followed by the
        special symbol 'EOL' in the state transition table. 'EOL' is short for 'end of line'; since it is capitalized and all our input texts are lower-case, it will be unambiguous.
        """
        pass


    def get_starters(self):
        """
        Return a list of all of the n-grams that start any sentence we've seen.
        The resulting list may contain duplicates, because one n-gram may start
        multiple sentences.
        """
        pass
    

    def get_stoppers(self):
        """
        Return a list of all the n-grams that stop any sentence we've seen.
        The resulting value may contain duplicates, because one n-gram may stop
        multiple sentences.
        """
        pass


    def get_successors(self, ngram):
        """
        Return a list of words that may follow a given n-gram.
        The resulting list may contain duplicates, because each
        n-gram may be followed by different words. For example,
        suppose an author has the following sentences:
        'the dog dances quickly'
        'the dog dances with the cat'
        'the dog dances with me'

        If n=3, then the n-gram 'the dog dances' is followed by
        'quickly' one time, and 'with' two times.

        If the given state never occurs, return an empty list.
        """
        pass
    

    def get_all_ngrams(self):
        """
        Return all the possible n-grams, or n-word sequences, that we have seen
        across all sentences.
        
        Probably a one-line method.
        """
        pass

    
    def has_successor(self, ngram):
        """
        Return True if the given ngram has at least one possible successor
        word, and False if it does not. This is another way of asking
        if we have ever seen a given ngram, because ngrams with no successor
        words must not have occurred in the training sentences.
        """
        pass
    
    
    def get_random_successor(self, ngram):
        """
        Given an n-gram, randomly pick from the possible words
        that could follow that n-gram. The randomness should take into
        account how likely a word is to follow the given n-gram.
        For example, if n=3 and we train on these three sentences:
        'the dog dances quickly'
        'the dog dances with the cat'
        'the dog dances with me'
        
        and we call get_random_next_word() for the state 'the dog dances',
        we should get 'quickly' about 1/3 of the time, and 'with' 2/3 of the time.
        """
        pass
    

    def babble(self):
        """
        Generate a random sentence using the following algorithm:
        
        1: Pick a starter ngram. This is the current ngram, and also 
        the current sentence so far.
        Suppose the starter ngram is 'a b c'
        
        2: Choose a successor word based on the current ngram.
        3: If the successor word is 'EOL', then return the current sentence.
        4: Otherwise, add the word to the end of the sentence
        (meaning sentence is now 'a b c d')
        5: Also add the word to the end of the current ngram, and 
        remove the first word from the current ngram.
        This produces 'b c d' for our example.
        6: Repeat step #2 until you generate 'EOL'.
        """
        pass
            

def main(n=3, filename='tests/test1.txt', num_sentences=5):
    """
    Simple test driver.
    """
    
    print('Currently running on ',filename)
    babbler = Babbler(n)
    babbler.add_file(filename)
        
    print(f'num starters {len(babbler.get_starters())}')
    print(f'num ngrams {len(babbler.get_all_ngrams())}')
    print(f'num stoppers {len(babbler.get_stoppers())}')
    for _ in range(num_sentences):
        print(babbler.babble())

# to execute this script, in your terminal, enter: python3 babbler.py
# you can optionally provide up to 3 arguments: (n, filename, num_sentences)
if __name__ == '__main__': 
    print("Entered arguments: ",sys.argv)
    sys.argv.pop(0) # remove the first parameter, which should be babbler.py, the name of the script
    # -------default values -----------
    n = 3
    filename = 'tests/test1.txt'
    num_sentences = 5
    #----------------------------------
    if len(sys.argv) > 0: # if any argumetns are passed, first is assumed to be n
        n = int(sys.argv.pop(0))
    if len(sys.argv) > 0: # if any more were passed, the next is assumed to be the filename
        filename = sys.argv.pop(0)
    if len(sys.argv) > 0: # if any more were passed, the next is assumed to be number of sentences to be generated 
        num_sentences = int(sys.argv.pop(0))
    main(n, filename, num_sentences) # now we call main with all the actual or default arguments